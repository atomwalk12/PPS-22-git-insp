# Application configuration
gitinsp {
  models {
    provider = "ollama"  # Available options: "Ollama", "Gemini" and "Claude"
    default-model = "qwen2.5-coder-32b" #"qwen3-32b"  # "deepseek-r1-32b" or "qwen2.5-coder-32b"
  }
  
  ollama {
    url = "http://localhost:11434/"
  }

  gemini {
    model = "gemma3"
    location = "europe-west2"
    project = "gitinsp"
  }

  claude {
    antrophic-api-key = "CLAUDE_API_KEY"
    model = "claude-3-5-sonnet-20240620"
  }

  qdrant {
    port = 6334
    host = "localhost"
  }

  reranker { # query embedding model
    min-score = -2
    model = "jina-reranker-v2-base-multilingual" #https://huggingface.co/jinaai/jina-reranker-v2-base-multilingual
    max-length = 1024
    tokenizer-path = "./reranker/jina-reranker-v2-base-multilingual/tokenizer.json"
    model-path = "./reranker/jina-reranker-v2-base-multilingual/onnx/model.onnx"
    max-results = 3
    normalize-scores = false
    use-gpu = false
  }

  code-embedding { # index generation model
    model = "unclemusclez/jina-embeddings-v2-base-code"
    size = 768,
    max-results = 30,
    min-score = 0.5
    chunk-size = 1500 # corresponds to about 300 tokens as the token to character ratio is ~5:1
    chunk-overlap = 562 # The 1500 tokens is approx. 40 lines of code, overlap is 15 lines.
    # SEE https://web.archive.org/web/20250214190630/https://docs.sweep.dev/blogs/chunking-2m-files
  }
  text-embedding { # index generation model
    model = "avr/sfr-embedding-mistral"
    size = 4096,
    max-results = 30,
    min-score = 0.5
    chunk-size = 1500 # or 1000
    chunk-overlap = 562 # or 200
  }

  rag {
    use-dynamic-filter = true # checks whether to retrieve code using specific languages (i.e. python, java, c++, scala)
    filter-strategy = "llm" # Available options: "llm", "none"
    use-conditional-rag = true # asks a model whether to retrieve code from the database or skip it
    model = "gemma3" # the model used to query conditional RAG and dynamic filter
  }

  chat {
    memory = 30 # NOTE: this is the number of messages to keep in the chat history
  }

  uithub {
    read-timeout = 6000000 # 100 minutes
    connection-timeout = 6000000 # 100 minutes
    index-tokens = 10000000 # max tokens to consider when building the index
    view-tokens = 10000000 # max tokens to consider when fetching a repository
  }

  request {
    timeout = 60000 # seconds
  }
}


akka {
  http {
    server {
      request-timeout = 30 minutes
      idle-timeout = 30 minutes
    }

    # For client requests if applicable
    client {
      connecting-timeout = 30 minutes
      idle-timeout = 30 minutes
    }
  }

  # Stream specific timeouts
  stream {
    materializer {
      subscription-timeout {
        mode = warn
        timeout = 5 minutes
      }
    }
  }
}
