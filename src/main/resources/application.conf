# Application configuration
tinygpt {
  models {
    default-model = "qwen2.5-coder-32b"  # "llama3.3" # "deepseek-r1-32b"
  }
  
  ollama {
    url = "http://localhost:11434/"
  }
}
